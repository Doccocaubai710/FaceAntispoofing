{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACJRSdkJjhKB",
        "outputId": "6e697585-ac49-4340-d9f9-1d7b4fbb3328"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LYttvZIriFLg"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.backends.cudnn as cudnn\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2_bVrNpi1_-",
        "outputId": "39fe25d7-9f65-462b-db00-697934b944ee"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0WAu0Qei3o9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "live_lbls = [0,1,6]\n",
        "class AsymAdditiveMarginSoftmax(nn.Module):\n",
        "    def __init__(self, in_features, out_features, s=30, ml=0.4,ms=0.1):\n",
        "        super(AsymAdditiveMarginSoftmax, self).__init__()\n",
        "        self.s = s\n",
        "        self.ml = ml\n",
        "        self.ms = ms\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.fc = nn.Linear(in_features, out_features, bias=False)\n",
        "    def forward(self, x, labels):\n",
        "        assert len(x) == len(labels)\n",
        "        assert torch.min(labels) >= 0\n",
        "        assert torch.max(labels) < self.out_features\n",
        "        m = torch.tensor([[self.ml if lbl in live_lbls else self.ms for lbl in labels]]).to(device)\n",
        "        self.fc.weight.data = F.normalize(self.fc.weight.data, p=2, dim=1)\n",
        "        x = F.normalize(x, p=2, dim=1)\n",
        "        wf = self.fc(x)\n",
        "        out = F.softmax(self.s*wf)\n",
        "        numerator = self.s * (torch.diagonal(wf.transpose(0, 1)[labels]) - m)\n",
        "        excl = torch.cat([torch.cat((wf[i, :y], wf[i, y+1:])).unsqueeze(0) for i, y in enumerate(labels)], dim=0)\n",
        "        denominator = torch.exp(numerator) + torch.sum(torch.exp(self.s * excl), dim=1)\n",
        "        L = numerator - torch.log(denominator)\n",
        "        return out, -torch.mean(L)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0qVV94dc6XS"
      },
      "outputs": [],
      "source": [
        "from torchvision.models.resnet import resnet18\n",
        "\n",
        "class SiameseNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SiameseNetwork, self).__init__()\n",
        "        self.encoder = resnet18(pretrained=True)\n",
        "        self.encoder.requires_grad = False\n",
        "        self.encoder.fc = nn.Sequential()\n",
        "        self.ams = AsymAdditiveMarginSoftmax(512,9)\n",
        "    def forward_once(self,input,labels):\n",
        "        f = self.encoder(input)\n",
        "        out, loss = self.ams(f,labels)\n",
        "        return out, f, loss\n",
        "    \n",
        "    def forward(self, input1, input2,labels):\n",
        "        out1, f1, loss1 = self.forward_once(input1,labels)\n",
        "        out2, f2, loss2 = self.forward_once(input2,labels)\n",
        "        f1_norm = F.normalize(f1,p=2,dim=1)\n",
        "        f2_norm = F.normalize(f2,p=2,dim=1)\n",
        "        loss =  loss1 + loss2 + torch.mean(torch.norm(f1_norm-f2_norm))\n",
        "        return out1, out2, loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6c1k0XKljEVJ"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "class SiameseNetworkDataset(Dataset):\n",
        "    def __init__(self,imageFolderDataset,transform):\n",
        "        self.imageFolderDataset = imageFolderDataset    \n",
        "        self.transform = transform\n",
        "    def __getitem__(self,index):   \n",
        "        data = self.imageFolderDataset.imgs[index]\n",
        "        img = Image.open(data[0])\n",
        "        img0 = self.transform[0](img)\n",
        "        img1 = self.transform[1](img)\n",
        "        return img0, img1, data[1]\n",
        "    def __len__(self):\n",
        "        return len(self.imageFolderDataset.imgs)\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self,imageFolderDataset,transform):\n",
        "        self.imageFolderDataset = imageFolderDataset    \n",
        "        self.transform = transform\n",
        "    def __getitem__(self,index):   \n",
        "        data = self.imageFolderDataset.imgs[index]\n",
        "        img = Image.open(data[0])\n",
        "        img = self.transform(img)\n",
        "        return img, data[1]\n",
        "    def __len__(self):\n",
        "        return len(self.imageFolderDataset.imgs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TkEIvR5ijH4S"
      },
      "outputs": [],
      "source": [
        "from torchvision.transforms.transforms import CenterCrop\n",
        "import time\n",
        "import copy\n",
        "from torchvision import datasets, transforms\n",
        "import os\n",
        "import torch\n",
        "\n",
        "data_transforms = {\n",
        "    'train': [\n",
        "        transforms.Compose([\n",
        "          transforms.RandomRotation(180),\n",
        "          transforms.RandomHorizontalFlip(p=0.5),\n",
        "          transforms.RandomCrop(100),\n",
        "          transforms.ToTensor(),\n",
        "        ]),\n",
        "        transforms.Compose([\n",
        "          transforms.RandomRotation(180),\n",
        "          transforms.RandomHorizontalFlip(p=0.5),\n",
        "          transforms.RandomCrop(100),\n",
        "          transforms.ToTensor(),\n",
        "        ]),\n",
        "    ],\n",
        "    'test': transforms.Compose([\n",
        "          transforms.RandomRotation(180),\n",
        "          transforms.RandomHorizontalFlip(p=0.5),\n",
        "          transforms.RandomCrop(100),\n",
        "          transforms.ToTensor(),\n",
        "        ]),\n",
        "}\n",
        "data_dir = '/content/drive/MyDrive/casia'\n",
        "image_datasets = {\n",
        "    'train': datasets.ImageFolder(os.path.join(data_dir, 'train')),\n",
        "     'test': datasets.ImageFolder(os.path.join(data_dir, 'test'))\n",
        "}\n",
        "siameseDataset = SiameseNetworkDataset(image_datasets['train'],data_transforms['train'])\n",
        "testDataset = TestDataset(image_datasets['test'], data_transforms['test'])\n",
        "dataloaders = {\n",
        "    'train': torch.utils.data.DataLoader(siameseDataset,shuffle=True,num_workers=2),\n",
        "    'test': torch.utils.data.DataLoader(testDataset,shuffle=True,num_workers=2)\n",
        "}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train','test']}\n",
        "class_names = image_datasets['train'].classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MU3b90pVwn4Z"
      },
      "outputs": [],
      "source": [
        "def imshow(img, text=None):\n",
        "    npimg = img.numpy()\n",
        "    plt.axis(\"off\")\n",
        "    if text:\n",
        "        plt.text(75, 8, text, style='italic',fontweight='bold',\n",
        "            bbox={'facecolor':'white', 'alpha':0.8, 'pad':10})\n",
        "        \n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()    \n",
        "\n",
        "def show_plot(iteration,loss):\n",
        "    plt.plot(iteration,loss)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "id": "-TkCM5Z-wTac",
        "outputId": "48b96bdf-88ab-4509-d501-e4739f3251f6"
      },
      "outputs": [],
      "source": [
        "vis_dataloader = torch.utils.data.DataLoader(siameseDataset,\n",
        "                        shuffle=True,\n",
        "                        num_workers=2,\n",
        "                        batch_size=8)\n",
        "example_batch = next(iter(vis_dataloader))\n",
        "concatenated = torch.cat((example_batch[0], example_batch[1]),0)\n",
        "imshow(torchvision.utils.make_grid(concatenated))\n",
        "print(example_batch[2].numpy().reshape(-1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "4ssplXYqDIaN",
        "outputId": "c6c8801d-828f-4479-f90e-68656566c69e"
      },
      "outputs": [],
      "source": [
        "vis_dataloader = torch.utils.data.DataLoader(testDataset,\n",
        "                        shuffle=True,\n",
        "                        num_workers=2,\n",
        "                        batch_size=8)\n",
        "example_batch = next(iter(vis_dataloader))\n",
        "concatenated = example_batch[0]\n",
        "imshow(torchvision.utils.make_grid(concatenated))\n",
        "print(example_batch[1].numpy().reshape(-1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i86Fz9nGfzXM"
      },
      "outputs": [],
      "source": [
        "loss_history_train = []\n",
        "loss_history_test = []\n",
        "acc_history_train = []\n",
        "acc_history_test = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIVyvlOcjU9w",
        "outputId": "8e0176e3-7d79-4a4c-e848-7fd712dba74d"
      },
      "outputs": [],
      "source": [
        "def train_model(model, optimizer, scheduler, num_epochs):\n",
        "    since = time.time()\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "        print('-' * 40)\n",
        "        for phase in ['train' , 'test']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "            for dataloader in dataloaders[phase]:\n",
        "                optimizer.zero_grad()\n",
        "                if phase == 'train':\n",
        "                  inputs1, inputs2, labels = dataloader\n",
        "                  inputs1 = inputs1.to(device)\n",
        "                  inputs2 = inputs2.to(device)\n",
        "                  labels = labels.to(device)\n",
        "                  out1, out2, loss = model(inputs1, inputs2, labels)\n",
        "                  loss.backward()\n",
        "                  optimizer.step()\n",
        "                  _, preds = torch.max(out1,1)\n",
        "                  running_corrects += torch.sum(preds == labels.data)\n",
        "                  running_loss += loss.item() * inputs1.size(0)\n",
        "                else:\n",
        "                  inputs, labels = dataloader\n",
        "                  inputs = inputs.to(device)\n",
        "                  labels = labels.to(device)\n",
        "                  with torch.no_grad():\n",
        "                    out, f, loss = net.forward_once(inputs, labels)\n",
        "                  _, preds = torch.max(out,1)\n",
        "                  running_corrects += torch.sum(preds == labels.data)\n",
        "                  running_loss += loss.item() * inputs.size(0)\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects / dataset_sizes[phase]\n",
        "            if phase == 'train':\n",
        "              scheduler.step()\n",
        "              loss_history_train.append(epoch_loss)\n",
        "              acc_history_train.append(epoch_acc.cpu().detach().numpy())\n",
        "            else:\n",
        "              loss_history_test.append(epoch_loss)\n",
        "              acc_history_test.append(epoch_acc.cpu().detach().numpy())\n",
        "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "            if phase == 'test' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "    print(f'Best val Acc: {best_acc:4f}')\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model\n",
        "net = SiameseNetwork().to(device)\n",
        "optimizer = optim.SGD(net.parameters(), lr = 0.002 )\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=90, gamma=0.5)\n",
        "net = train_model(net,optimizer,exp_lr_scheduler,200)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1flLH1vgbqB1"
      },
      "outputs": [],
      "source": [
        "plt.plot(loss_history_train,c='r')\n",
        "plt.plot(loss_history_test,c='b')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxJqhKHgiLt6"
      },
      "outputs": [],
      "source": [
        "plt.plot(acc_history_train,c='r')\n",
        "plt.plot(acc_history_test,c='b')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjo-swx6Nrxc"
      },
      "outputs": [],
      "source": [
        "class PatchNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PatchNet,self).__init__()\n",
        "        self.encoder = resnet18()\n",
        "        self.encoder.fc = nn.Sequential()\n",
        "        self.fc = nn.Linear(512,9, bias=False)\n",
        "    def forward(self,x):\n",
        "        x = self.encoder(x)\n",
        "        self.fc.weight.data = F.normalize(self.fc.weight.data, p=2, dim=1) \n",
        "\n",
        "        x = F.normalize(x, p=2, dim=1)\n",
        "\n",
        "        wf = self.fc(x)\n",
        "        x = F.softmax(30 * wf)\n",
        "        return x\n",
        "\n",
        "model = PatchNet().cuda()\n",
        "model.encoder = net.encoder\n",
        "model.fc = net.ams.fc\n",
        "torch.save(model,'/content/drive/MyDrive/casia/patchnet.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azDNvnZcaao7"
      },
      "outputs": [],
      "source": [
        "running_corrects = 0\n",
        "for i, (img1, label) in enumerate(dataloaders['test']):\n",
        "        img1, label = img1.cuda(), label.cuda()\n",
        "        with torch.no_grad():\n",
        "            output = model(img1)\n",
        "            _, preds = torch.max(output,1)\n",
        "        running_corrects += torch.sum(preds == label.data)\n",
        "acc = running_corrects/dataset_sizes['test']\n",
        "print(f'Acc: {acc:.4f}')\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9aSeWuglbEDu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "PatchNet.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
